#!/usr/bin/env python3

import asyncio
import json
import os
import subprocess
import sys
from typing import Dict, Any
from dotenv import load_dotenv
from openai import OpenAI

# Load environment variables
load_dotenv(override=True)

class MCPOpenAIClient:
    def __init__(self, model="gpt-5-mini"):
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.model = model  # Configurable model
        self.mcp_tools = []
        self.process = None
        
    async def connect_to_mcp_server(self):
        """Connect to the MCP server and get available tools."""
        try:
            # Start MCP server process - Windows compatible
            self.process = subprocess.Popen(
                [sys.executable, "-m", "mcp_server.main", "stdio"],
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                # Inherit parent's stderr to avoid filling an unread PIPE buffer
                stderr=None,
                text=True,
                encoding="utf-8",
                cwd=os.getcwd()  # Ensure we're in the right directory
            )
            
            # Initialize the session
            init_request = {
                "jsonrpc": "2.0",
                "id": 1,
                "method": "initialize",
                "params": {
                    "protocolVersion": "2024-11-05",
                    "capabilities": {},
                    "clientInfo": {
                        "name": "openai-mcp-client",
                        "version": "1.0.0"
                    }
                }
            }
            
            self.process.stdin.write(json.dumps(init_request) + "\n")
            self.process.stdin.flush()
            
            init_response = self.process.stdout.readline()
            init_data = json.loads(init_response)
            
            # Send initialized notification
            initialized_msg = {
                "jsonrpc": "2.0",
                "method": "notifications/initialized"
            }
            self.process.stdin.write(json.dumps(initialized_msg) + "\n")
            self.process.stdin.flush()
            
            # Get available tools
            tools_request = {
                "jsonrpc": "2.0",
                "id": 2,
                "method": "tools/list",
                "params": {}
            }
            
            self.process.stdin.write(json.dumps(tools_request) + "\n")
            self.process.stdin.flush()
            
            tools_response = self.process.stdout.readline()
            tools_data = json.loads(tools_response)
            
            if "result" in tools_data:
                self.mcp_tools = tools_data["result"].get("tools", [])
                print(f"Available MCP tools: {[tool['name'] for tool in self.mcp_tools]}")
                return True
            else:
                return False
                    
        except Exception as e:
            print(f"Error connecting to MCP server: {e}")
            return False
    
    async def call_mcp_tool(self, tool_name: str, arguments: Dict[str, Any]):
        """Call a specific MCP tool."""
        try:
            tool_call = {
                "jsonrpc": "2.0",
                "id": 3,
                "method": "tools/call",
                "params": {
                    "name": tool_name,
                    "arguments": arguments
                }
            }
            
            self.process.stdin.write(json.dumps(tool_call) + "\n")
            self.process.stdin.flush()
            
            response = self.process.stdout.readline()
            response_data = json.loads(response)
            
            if "result" in response_data:
                return response_data["result"]
            else:
                # Return structured error so caller can still send a tool message
                return {"isError": True, "error": response_data.get("error", response_data)}
                
        except Exception as e:
            # Return structured error so caller can still send a tool message
            print(f"Error calling tool: {e}")
            return {"isError": True, "error": str(e)}
    
    def create_openai_tools_schema(self):
        """Convert MCP tools to OpenAI tools schema."""
        openai_tools = []
        
        for tool in self.mcp_tools:
            openai_tool = {
                "type": "function",
                "function": {
                    "name": tool["name"],
                    "description": tool["description"],
                    "parameters": tool["inputSchema"]
                }
            }
            openai_tools.append(openai_tool)
        
        return openai_tools
    
    async def chat_with_tools(self, message: str):
        """Chat with OpenAI using MCP tools with conversation loop."""
        try:
            # Convert MCP tools to OpenAI format
            openai_tools = self.create_openai_tools_schema()
            
            # Initialize conversation
            messages = [
                {
                    "role": "system",
                    "content": "You are a helpful assistant with access to game development tools. If the user asks for multiple things, execute them one at a time in sequence.\n\nTOOL USAGE:\n- 'generate_initial_storyline': Creates a storyline and saves it to storyline.json\n- 'generate_sprites_from_storyline': Generates character sprites from existing storyline.json\n- 'list_directory': Lists files in a directory\n- 'read_file': Reads file contents\n\nExecute only the tool the user requests. Do not call the same tool multiple times."
                },
                {
                    "role": "user",
                    "content": message
                }
            ]
            
            max_iterations = 10  # Prevent infinite loops
            iteration = 0
            last_tool_called = None
            
            while iteration < max_iterations:
                iteration += 1
                
                # Create chat completion with tools
                response = self.openai_client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    tools=openai_tools,
                    tool_choice="auto"
                )
                
                message_response = response.choices[0].message
                
                # Add the AI's response to conversation
                messages.append(message_response)
                
                # Handle tool calls
                if message_response.tool_calls:
                    print(f"ðŸ”„ Step {iteration}: Processing {len(message_response.tool_calls)} tool(s)")
                    
                    tool_results = []
                    
                    for tool_call in message_response.tool_calls:
                        tool_name = tool_call.function.name
                        tool_args = json.loads(tool_call.function.arguments)
                        
                        # Prevent calling the same tool multiple times in a row
                        if tool_name == last_tool_called:
                            print(f"âš ï¸ Skipping duplicate {tool_name} call")
                            continue
                        
                        print(f"âš™ï¸ Executing {tool_name}...")
                        
                        # Call the MCP tool
                        result = await self.call_mcp_tool(tool_name, tool_args)
                        
                        if result:
                            tool_results.append({
                                "tool_call_id": tool_call.id,
                                "role": "tool",
                                "content": str(result)
                            })
                            print(f"âœ… {tool_name} completed")
                            last_tool_called = tool_name
                    
                    # Add tool results to conversation
                    messages.extend(tool_results)
                    
                    # Continue the conversation to see if more tools are needed
                    continue
                else:
                    # No more tool calls, return the final response
                    return message_response.content
                    
            # If we hit max iterations, return what we have
            return "âš ï¸ Reached maximum iterations. Some tasks may not be complete."
                
        except Exception as e:
            return f"âŒ Error in chat: {e}"
    
    def cleanup(self):
        """Clean up the MCP server process."""
        if self.process:
            self.process.terminate()
            self.process.wait()

async def main():
    """Main interactive chat function."""
    # You can change the model here: "gpt-5-nano", "gpt-5", "gpt-5-mini", "gpt-4o", etc.
    client = MCPOpenAIClient(model="gpt-5-mini")
    
    # Check if API key is set
    if not os.getenv("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY") == "your_openai_api_key_here":
        print("âŒ Please set your OpenAI API key in the .env file")
        print("   Edit .env and replace 'your_openai_api_key_here' with your actual API key")
        return

    print("Starting Persistence MCP client...")
    print(f"Using model: {client.model}")
    print("Type 'quit' to exit\n")
    
    # Initialize MCP server once
    connected = await client.connect_to_mcp_server()
    if not connected:
        print("âŒ Failed to connect to MCP server")
        return

    print("Ready! Starting operations...\n")
    
    try:
        while True:
            # Check if we're in an interactive terminal
            if not sys.stdin.isatty():
                print("âŒ Interactive mode requires a terminal.")
                break
                
            message = input("ðŸ’¬ User: ").strip()
            
            if message.lower() == 'quit':
                print("Goodbye! Shutting down MCP server...")
                break
            elif not message:
                continue
            
            print("Chat: ", end="", flush=True)
            response = await client.chat_with_tools(message)
            print(response)
            print()  # Add spacing between messages
            
    except KeyboardInterrupt:
        print("\nGoodbye! Shutting down MCP server...")
    except Exception as e:
        print(f"\nError: {e}")
    finally:
        # Clean up
        client.cleanup()

if __name__ == "__main__":
    asyncio.run(main())
